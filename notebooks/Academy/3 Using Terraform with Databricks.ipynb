{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Terraform with Databricks\n",
    "\n",
    "In this lab you will learn how to:\n",
    "* Install and configure open source Terraform\n",
    "* Remotely administer Databricks using open source Terraform and Terraform Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Terraform is a software tool that allows you to define infrastructure as code. Terraform integrates with hundreds of upstream APIs including Databricks. Most of the resources exposed by Databricks APIs can be managed with Terraform.\n",
    "\n",
    "Terraform is accessible in two ways:\n",
    "* A free, open source self-managed tool available in binary form that can be run in a variety of operating systems\n",
    "* A managed SaaS platform known as **Terraform Cloud** that offers free and paid tiers\n",
    "\n",
    "We will explore both options in this lab, but we'll starting with the self-managed version. During that time, we'll also get acquainted with the constructs of a Terraform environment and its operation, before seeing how it all fits in with Terraform Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open source Terraform\n",
    "\n",
    "Hashicorp offers a completely free version of Terraform that you download and manage on your own. Users typically install it in their own environment, where they can invoke it manually or integrate it with upstream CI/CD processes. In this lab, we will take advantage of the execution environment provided by the attached all-purpose cluster for the purpose of demonstrating installation and usage.\n",
    "\n",
    "When managing Terraform on your own, there's a couple important considerations to keep in mind. The details of these fall outside the scope of this lab, but we mention them here so that you will be aware of them if you choose to go down this route.\n",
    "\n",
    "* **Configuration files:** Terraform configurations are defined by a collection of text files written in Terraform language. Since this is infrastructure as code, these files should be treated like any other code. It's definitely a good idea to manage them using revision control.\n",
    "* **Authentication:** because Terraform uses Databricks APIs, it needs authentication credentials. If you happen to be using the Databricks CLI in the same environment, Terraform can use its authentication setup. Otherwise, environment variables are generally considered the safest option. As a final resort, credentials can be embedded in the configuration files themselves, but be careful with this since it's easy to inadvertently distribute to others directly or through revision control.\n",
    "* **State management:** Terraform tracks and records the current state of the system using a *backend*, and this part is crucial for Terraform to function correctly and reliably. The backend storage must be persistent (at least for the life of the resources it manages) and accessible by all who may be managing the configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classroom Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Classroom-Setup-03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the DA object components\n",
    "print(f\"Username: {DA.username}\")\n",
    "print(f\"Catalog Name: {DA.catalog_name}\")\n",
    "print(f\"Schema Name: {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location: {DA.paths.datasets}\")\n",
    "print(f\"Secondary Principal: {DA.iam.secondary}\")\n",
    "print(f\"Cluster Name: {DA.cluster_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh wget -P /tmp https://releases.hashicorp.com/terraform/1.2.8/terraform_1.2.8_linux_amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh unzip -d $VIRTUAL_ENV/bin /tmp/terraform_1.2.8_linux_amd64.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh terraform -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA.get_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Databricks Personal Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the folder and file path\n",
    "folder_path = './terraform_resources'\n",
    "file_path = os.path.join(folder_path, 'databricks.tf')\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write the Terraform configuration to the file\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "            provider \"databricks\" {{\n",
    "                host = \"{os.getenv['DATABRICKS_HOST']}\"\n",
    "                token = \"{os.getenv['DATABRICKS_TOKEN']}\"\n",
    "                }}\n",
    "            \"\"\")\n",
    "    \n",
    "print(f\"Terraform configuration written to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create folder and file path\n",
    "folder_path = './terraform_resources'\n",
    "file_path = os.path.join(folder_path, 'databricks.tf')\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write the Terraform configuration to the file\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "            terraform{\n",
    "                required_providers {\n",
    "                    databricks = {\n",
    "                        source  = \"databricks/databricks\"\n",
    "                        version = \"~> 1.0.0\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            backend \"local\" {\n",
    "                path = \"/tmp/terraform/terraform.tfstate\"\n",
    "            }\n",
    "            \"\"\")\n",
    "    \n",
    "print(f\"Terraform configuration written to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Terraform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh terraform -chdir=./terraform_resources init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \"${DA.schema_name}\" AS Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring a new schema\n",
    "For those who followed along with the labs Using Databricks Utilities and CLI and Using Databricks APIs, let's work toward definined a Terraform configuration that builds the elements that we created in those labs. As a first step, let's establish a new schema in the main catalog named myschema_tfos.\n",
    "\n",
    "To add elements to a Terraform configuration, we can simply add an arbitrarily named .tf file to the folder. In this case we will simply add the file schema.tf to specify the schema.\n",
    "\n",
    "Terraform configuration files are written in the Terraform language, which is built on a simple, declarative syntax. The configuration files describe the desired state of the system, which makes defining and managing the system extremely easy for an admin since Terraform manages all the changes needed to get the system to the desired state.\n",
    "\n",
    "Because we're running this in the context of a notebook, there's some extra code wrapped around the actual configuration; the essence of the configuration is found within the triple-quotation fences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.put(\n",
    "    \"/terraform/schema.tf\",\n",
    "    \"\"\"\n",
    "    resource \"databricks_schema\" \"myschema\" {\n",
    "        catalog_name = \"main\"\n",
    "        name         = \"myschema_tfos\"\n",
    "        comment      = \"This schema is managed by Terraform Open Source\"\n",
    "    }\n",
    "    \"\"\",\n",
    "    True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the folder and file path\n",
    "folder_path = './terraform_resources'\n",
    "file_path = os.path.join(folder_path, 'table.tf')\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write the Terraform configuration to the file\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "            resource \"databricks_sql_table\" \"Terraform_Table\" {\n",
    "                catalog_name = \"dbacademy\"\n",
    "                schema_name  = \"gifted_target\"\n",
    "                name         = \"terraform_table\"\n",
    "                table_type  = \"MANAGED\"\n",
    "                data_source_format = \"DELTA\"\n",
    "                cluster_id = \"1211-060256-y75n00eh\n",
    "                \n",
    "                column {\n",
    "                    name = \"id\"\n",
    "                    type = \"int\"\n",
    "                    comment = \"Primary Key\"\n",
    "                }\n",
    "                column {\n",
    "                    name = \"name\"\n",
    "                    type = \"string\"\n",
    "                    comment = \"Name of gifted student\"\n",
    "                }\n",
    "                column {\n",
    "                    name = \"score\"\n",
    "                    type = \"float\"\n",
    "                    comment = \"Score obtained by the student\"\n",
    "                }\n",
    "            }\n",
    "            \"\"\")\n",
    "    \n",
    "print(f\"Terraform configuration written to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh terraform -chdir=./terraform_resources plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh terraform -chdir=./terraform_resources apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh terraform -chdir=./terraform_resources apply -destroy -auto-approve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh rm -rf ./terraform_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh rm -rm ./var"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
